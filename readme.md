# PensieveÂ App â€” Audioâ€‘capture Proofâ€‘ofâ€‘Concept

> **StatusÂ :Â parked (2025â€‘06â€‘21)**
>
> Development is on hold while the audioâ€‘path issues are investigated. This
> README captures everything that currently works, commands to reproduce the
> tests, observations, and the open problems so itâ€™s easy to pick up again.

---

## 1Â Â Project layout

| Path                        | What it is                                                                                                                                            |
| --------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------- |
| `mac-helper/`               | Standâ€‘alone Swift helper built with **ScreenCaptureKit** + **AVFoundation**. Captures a single Chrome tab **+ mic** and writes raw PCM to **stdout**. |
| `native/`                   | Nodeâ€‘API bridge (`bridge.mm`) that *used* to call ScreenCaptureKit directly. **Deprecated** in favour of the Swift helper.                            |
| `renderer.js`               | Electron renderer â€“ spawns the helper, reâ€‘chunks stdout every *N*â€¯ms and sends baseâ€‘64 blobs over a WebSocket.                                        |
| `speech_to_text_service.py` | FastAPI handler â†’ decodes b64 â†’ `ffmpeg` â†’ Whisper.                                                                                                   |

---

## 2Â Â Prerequisites

* **macOSÂ 13Â Ventura** or newer (ScreenCaptureKit)
* XcodeÂ 15 commandâ€‘line tools (for SwiftPM)
* Homebrew `ffmpeg 7.1+` (with `ffplay` for quick listening tests)
* NodeÂ 23Â +Â npm, PythonÂ 3.11, virtualâ€‘env
* Chrome running with an active *meet.google.com* or YouTube tab

---

## 3Â Â Build &Â run

```bash
# 1âƒ£Â Install JS deps & build Electron bits
npm install
npm run rebuild-native   # still needed for the Nodeâ€‘API shim (optional)

# 2âƒ£Â Build Swift helper (Release)
cd mac-helper
swift build -c release   # product is .build/release/AudioHelper
cd ..

# 3âƒ£Â Start backend (FastAPI) in a venv
uvicorn main:app --reload   # not committed, local only

# 4âƒ£Â Run the desktop UI
npm start                  # spawns Electron
```

---

## 4Â Â Lowâ€‘level audio tests  Â ðŸ”Š

These are **mustâ€‘run** before touching the JS side.

| Test             | Command                                             |                                               |            |
| ---------------- | --------------------------------------------------- | --------------------------------------------- | ---------- |
| **Dry tab only** | `./AudioHelper com.google.Chrome --dryâ€‘tab \`<br>\` | ffplay -f f32le -ar 48000 -ac 1 -\`           |            |
| **Dry mic only** | `./AudioHelper com.google.Chrome --dryâ€‘mic \`<br>\` | ffplay -f f32le -ar 48000 -ac 1 -\`           |            |
| **Dry merged**   | `./AudioHelper com.google.Chrome \`<br>\`           | ffmpeg -f f32le -ar 48000 -ac 1 -i - -f wav - | ffplay -\` |

./AudioHelper com.google.Chrome --dry-mic | ffmpeg -f s16le -ar 48000 -ac 2 -i - -f wav - | ffplay - ==> only tab audio
./AudioHelper com.google.Chrome --dry-tab | ffmpeg -f f32le -ar 48000 -ac 1 -i - -f wav - | ffplay - ==> only mic audio

> \:warning:Â At the moment all three commands play *whiteâ€‘noise like garbage* â†’
> proves the helper is emitting the **wrong format** (see Â§5).

---

## 5Â Â Findings so far

* **ScreenCaptureKit format**Â â€” without `cfg.audioCodec = .pcm` (macOSÂ 14+) the
  buffer we pull via `CMSampleBufferGetDataBuffer` is *not* raw Floatâ€‘32 PCM â€“
  likely AAC. Treating those bytes as floats â‡’ hiss.
* **Correct way** is to fetch the `AudioBufferList` from the `CMSampleBuffer`
  (QuickRecorder does this).
* **Merging path** â€“ current `AVEngine` converts mic/tap to Floatâ€‘32 mono and
  mixes 50/50, but still uses the bad tab bytes â†’ distorted output.
* **Backend** â€“ when fed a *good* 48Â kHzÂ f32le mono file Whisper works fine.

---

## 6Â Â Open problems / TODO

1. **Fix helper delegate**

   * Use `CMSampleBufferGetAudioBufferListWithRetainedBlockBuffer` and inspect
     the ASBD. Confirm format is `lpcm`, 32â€‘bit float, **nonâ€‘interleaved**.
2. **Force PCM in config** (macOSÂ 14):

   ```swift
   if #available(macOS 14.0, *) {
       cfg.audioCodec = .pcm
       cfg.audioChannelCount = 1
   }
   ```
3. **Verify with ffplay** â€“ repeat the three dry tests until they sound clean.
4. **Reâ€‘enable Electron pipeline** â€“ once stdout is correct, the rendererâ€™s
   baseâ€‘64 chunks should decode to valid wave and Whisper will align.
5. **Echo / local monitoring** â€“ optional: expose a gain slider; default to 0.

---

## 7Â Â Useful oneâ€‘liners

```bash
# Print ASBD from SBs to debug
log stream --predicate 'subsystem == "com.apple.audio"' --info

# Listen to helper output via sox (alternative to ffplay)
./AudioHelper com.google.Chrome | sox -t f32 -r 48k -c1 - -d
```

---

## 8Â Â Parking notice

Development paused **2025â€‘06â€‘21** after confirming that ScreenCaptureKit is
feeding compressed data. Next session should start with *StepÂ 1* in **Open
problems** above.

Happy hackingÂ â€” see you later!
*â€”â€¯A.*
